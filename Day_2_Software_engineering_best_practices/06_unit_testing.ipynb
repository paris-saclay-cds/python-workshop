{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several Python libraries dedicated to unit testing. \n",
    "The most common are:\n",
    "* [`unittest`](http://docs.python.org/library/unittest.html)\n",
    "* [`nose`](http://nosetest.org)\n",
    "* [`pytest`](http://pytest.org/)\n",
    "\n",
    "This course focuses on the use of `pytest`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "- [Testing principles](#Testing-principles)\n",
    "- [Unit tests](#Unit-tests)\n",
    "- [Writing a first test](#Writing-a-test)\n",
    "- [Configuring `pytest`](#Pytest-configuration)\n",
    "- [Test coverage](#Test-coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing principles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why should you write tests ?\n",
    "\n",
    "In general, tests are an **assessment of** both the **quality** and the **efficiency** of your code.\n",
    "\n",
    "Tests actually **define** the requirements of the code at various levels. From the basic method definition, to the full software validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What kind of tests should you write ?\n",
    "\n",
    "For each of these levels, a type of test exists :\n",
    "- unit tests\n",
    "- non-regression tests\n",
    "- pre-integration tests\n",
    "- integration tests\n",
    "- validation tests\n",
    "\n",
    "From this terminology, the unit tests are the basic elements, that should be run **before any commit** of the code. \n",
    "They are the one that will be the focus of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Driven Development (TDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a test\n",
    "\n",
    "A unit test written under `pytest` is a Python function or class whose name **starts with \"test\"** and that makes an hypothesis ones considers true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first test\n",
    "\n",
    "Let's right a basic file containing a function f, and the corresponding test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file my_first_test.py\n",
    "\n",
    "def f(a):\n",
    "    return a\n",
    "\n",
    "def test_a():\n",
    "    assert f(1) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file has been saved in the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls *.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Launching pytest is as easy as move to the right directory and using the command line\n",
    "\n",
    "    py.test\n",
    "    \n",
    "It will start a recursive search from the current directory for Python files, look for methods containing \"test\" and run them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a quick summary, use the quick option `-q`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on which test has been run, use the verbose option `-v`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic test `test_a` has passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional tests\n",
    "\n",
    "Let's now write a bunch of tests, introduce an error on `test_b` and re-run pytest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file my_second_test.py\n",
    "\n",
    "def f(a):\n",
    "    return a\n",
    "\n",
    "def test_a():\n",
    "    assert f(1) == 1\n",
    "    \n",
    "def test_b():\n",
    "    assert f(2) == 1\n",
    "\n",
    "def test_c():\n",
    "    assert f(3) == 1 + 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test -v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see pytest has *collected* and run 4 items, 1 from the first file, and 3 from the second. \n",
    "\n",
    "As expected, one test has failed.\n",
    "\n",
    "Therefore `pytest` shows the full traceback leading to the failure, and even gives the output value of the `f` method which can be useful for quick debugging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing errors and exceptions\n",
    "\n",
    "The philosophy of Python is to try something first and then decide what to do in case of an error. This is the reason behind Python Exceptions. They inform on the issue that was detected and help the user debug or catch it and find another way to deal with the issue.\n",
    "\n",
    "When testing a code, it is thus important to assess if these Exceptions are raised as they should be. However, since an exception raised but not caught in an environmment triggers an error, one cannot use the \"assert\" syntax but the context manager `pytest.raises` instead.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%file my_third_test.py\n",
    "\n",
    "import pytest\n",
    "\n",
    "def h(n):\n",
    "    if n < 0:\n",
    "        raise ValueError(\"Negative value detected\")\n",
    "    return n\n",
    "        \n",
    "def test_h():\n",
    "    assert h(1) == 1\n",
    "    \n",
    "def test_exception_h():\n",
    "    with pytest.raises(ValueError):\n",
    "        h(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test -v my_third_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytest configuration\n",
    "\n",
    "This part explains how to organize your tests for testing a module. It uses the `euclid` toy module created for this course and available in the base directory under `python-euclid2016/euclid`. \n",
    "\n",
    "At this point, it is easier to open a separate terminal, go to the `euclid` directory\n",
    "\n",
    "    cd ~/Desktop/python-euclid2016/euclid  # for the VM users\n",
    "\n",
    "and continue from there.\n",
    "\n",
    "***Remainder***: shell commands in the notebook are preceded with \"!\", **not** in a terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Depending on where you are at this point do not run this\n",
    "%cd ../euclid/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This directory contains a `Makefile` with three utility commands:\n",
    "\n",
    "    make clean     # to remove __pycache__ and .pyc files\n",
    "    make tests     # to run the tests\n",
    "    make coverage  # to run coverage tests (see next section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!make clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "In order to **visualize** the arborescence of the module and test directory, I recommend using the Linux utility `tree` which can be install in the VM with \n",
    "\n",
    "    sudo yum install -y tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except from the `Makefile`, there are two directories, the module `euclid` and the test directory `tests`.\n",
    "\n",
    "The `tests` directory contains \n",
    "\n",
    "* `__init__.py`  an **empty** file so that the tests are aware of the `euclid` model,\n",
    "* `test_mytrigo.py`  a file containing the tests for the functions in `mytrigo.py`\n",
    "* `conftest.py`  a pytest configuration file whose purpose is to **host the fixtures** for all tests\n",
    "\n",
    "***Note*** `conftest.py` do not need to be imported for pytest to use the fixtures. It is automatic.\n",
    "\n",
    "---\n",
    "\n",
    "### Content of `conftest.py`\n",
    "\n",
    "To visualize the content of the files, one can use\n",
    "\n",
    "    %load myfile.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test coverage\n",
    "\n",
    "A test coverage is a report on the number of lignes of a module that have been tested. Basically, a good coverage means much of your code has been run at least once during a test.\n",
    "\n",
    "To use coverage with pytest, one must first install\n",
    "    \n",
    "    sudo pip install pytest-cov\n",
    "\n",
    "Then the coverage test is run on the module, not on the tests itself. Here the module is `euclid`. before running the coverage test, one needs to be in the directory \n",
    "\n",
    "    ../python-euclid2016/euclid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!py.test --cov euclid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can see that `hello.py` and `mytime.py` are not covered by tests.\n",
    "\n",
    "However, the coverage of `mytime.py` is not 0, as all of the `__init__.py` since the **imports** present in the files trigger an evaluation of some of the lines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
